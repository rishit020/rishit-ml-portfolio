This project is my first step into machine learning data prep, but done completely in NumPy. I generated a fake dataset, added missing values on purpose, cleaned them up using imputation, normalized the features, filtered the data based on certain conditions, shuffled everything, and created a train/validation split. Even though tools like pandas make this easier, doing it in pure NumPy helped me understand what’s happening at a lower level and gave me more control over the data.

I built this to show that I’m comfortable with indexing, masking, reshaping, random operations, and vectorized math — all skills that carry directly into pandas, scikit-learn, and eventually deep learning frameworks like PyTorch and TensorFlow. This is the first project in my ML portfolio, and everything here builds the foundation for the more advanced work I’m moving toward.
